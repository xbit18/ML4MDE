{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0f3d1eb2",
      "metadata": {
        "id": "0f3d1eb2",
        "outputId": "a68ba4e7-2603-48f2-eb4d-578678d42156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss, accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from google.colab import drive\n",
        "from os.path import join\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "nltk.download('stopwords', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "73d229b2",
      "metadata": {
        "id": "73d229b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05474a95-a15a-4daa-cf06-1c016dc93352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive/', force_remount=False)\n",
        "DATA_PATH = '/content/drive/My Drive/Colab Notebooks/ML4MDE_Project/'\n",
        "\n",
        "\n",
        "file = join(DATA_PATH,'dataset.csv')\n",
        "df = pd.read_csv(file, header=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14b233b",
      "metadata": {
        "id": "e14b233b"
      },
      "source": [
        "<hr />\n",
        "<h2>Data Preprocessing</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "359245fb",
      "metadata": {
        "id": "359245fb"
      },
      "outputs": [],
      "source": [
        "contraction_mapping = {\n",
        "    \"ain't\": \"is not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\",\n",
        "    \"I'd've\": \"I would have\",\n",
        "    \"I'll\": \"I will\",\n",
        "    \"I'll've\": \"I will have\",\n",
        "    \"I'm\": \"I am\",\n",
        "    \"I've\": \"I have\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"this's\": \"this is\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"here's\": \"here is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\",\n",
        "}\n",
        "\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "def clean_text(text: str):\n",
        "    to_clean = text.lower()\n",
        "    to_clean = to_clean.replace('\"', '')\n",
        "    to_clean = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in to_clean.split(\" \")])\n",
        "    to_clean = re.sub(\"[^a-zA-Z]\", \" \", to_clean)\n",
        "    words = [word for word in to_clean.split() if word not in stop_words and len(word) > 1]\n",
        "    return \" \".join(words).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e3c5e167",
      "metadata": {
        "id": "e3c5e167"
      },
      "outputs": [],
      "source": [
        "df['comment_text'] = df['comment_text'].apply(clean_text)\n",
        "X = df['comment_text'].values\n",
        "y = df[df.columns[2:]].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fc8a3ed1",
      "metadata": {
        "id": "fc8a3ed1"
      },
      "outputs": [],
      "source": [
        "# TextVectorization\n",
        "MAX_FEATURES = 10000\n",
        "MAX_SEQUENCE = 100\n",
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length=MAX_SEQUENCE, output_mode='int')\n",
        "vectorizer.adapt(X)\n",
        "X = np.array(vectorizer(X))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# K-FOLD CROSS VALIDATION\n",
        "NUM_FOLDS = 2\n",
        "KF = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=10)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(MAX_FEATURES + 1, 32))\n",
        "\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='BinaryCrossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "\n",
        "index = 1\n",
        "\n",
        "for train_index, val_index in KF.split(X_train):\n",
        "  print(f\"Fold {index}\")\n",
        "  X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
        "  y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "  model.fit(X_fold_train, y_fold_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_fold_val, y_fold_val))\n",
        "\n",
        "  scores = model.evaluate(X_fold_val, y_fold_val)\n",
        "  print(f\"Validation Accuracy: {scores[1]*100:.2f}%\")\n",
        "  index += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCmKx74iFB9G",
        "outputId": "7a16f03e-94d4-4db1-eb3a-2ccf274566b9"
      },
      "id": "SCmKx74iFB9G",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1995/1995 [==============================] - 80s 38ms/step - loss: 0.1425 - accuracy: 0.9913 - val_loss: 0.1353 - val_accuracy: 0.9942\n",
            "Epoch 2/3\n",
            "1995/1995 [==============================] - 50s 25ms/step - loss: 0.1356 - accuracy: 0.9940 - val_loss: 0.1324 - val_accuracy: 0.9942\n",
            "Epoch 3/3\n",
            "1995/1995 [==============================] - 37s 18ms/step - loss: 0.1347 - accuracy: 0.9939 - val_loss: 0.1315 - val_accuracy: 0.9942\n",
            "1995/1995 [==============================] - 11s 6ms/step - loss: 0.1315 - accuracy: 0.9942\n",
            "Validation Accuracy: 99.4187%\n",
            "Epoch 1/3\n",
            "1995/1995 [==============================] - 50s 25ms/step - loss: 0.1315 - accuracy: 0.9941 - val_loss: 0.1339 - val_accuracy: 0.9940\n",
            "Epoch 2/3\n",
            "1995/1995 [==============================] - 52s 26ms/step - loss: 0.1312 - accuracy: 0.9927 - val_loss: 0.1344 - val_accuracy: 0.9940\n",
            "Epoch 3/3\n",
            "1995/1995 [==============================] - 35s 18ms/step - loss: 0.1303 - accuracy: 0.9923 - val_loss: 0.1333 - val_accuracy: 0.9940\n",
            "1995/1995 [==============================] - 12s 6ms/step - loss: 0.1333 - accuracy: 0.9940\n",
            "Validation Accuracy: 99.3968%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRsV2E5JNx9K",
        "outputId": "5d4e7b00-8bdf-498a-9078-dfdedf543297"
      },
      "id": "HRsV2E5JNx9K",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, None, 32)          352       \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 64)                16640     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25702 (100.40 KB)\n",
            "Trainable params: 25702 (100.40 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = vectorizer('You are ugly!')\n",
        "predict = model.predict(np.expand_dims(test, 0))\n",
        "(predict > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "O44NH5YNP9Hh"
      },
      "id": "O44NH5YNP9Hh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valutazione del modello sul set di test\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "labels = ['toxic', 'sever toxic', 'obscene', 'threat', 'insult', 'identity hate']\n",
        "\n",
        "# 1. Precision, Recall, F1-Score per ogni etichetta (0.5 valore di default comunemente utilizzato per la classificazione binaria)\n",
        "precision = precision_score(y_test, y_pred, average=None)\n",
        "recall = recall_score(y_test, y_pred, average=None)\n",
        "f1 = f1_score(y_test, y_pred, average=None)\n",
        "\n",
        "for i in range(len(precision)):\n",
        "    print(f'Label {labels[i]}: Precision = {precision[i]:.4f}, Recall = {recall[i]:.4f}, F1-Score = {f1[i]:.4f}')"
      ],
      "metadata": {
        "id": "GwQ5o0TTHMjY"
      },
      "id": "GwQ5o0TTHMjY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Hamming Loss\n",
        "# (L'Hamming Loss è una metrica utilizzata per valutare la precisione di un modello di classificazione multi-etichetta.\n",
        "# Essa misura la frazione di label classificate in modo scorretto rispetto al numero totale di label.\n",
        "# L'obiettivo è minimizzare questa metrica, quindi un valore più basso di Hamming Loss indica una migliore precisione.)\n",
        "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
        "print(f'Hamming Loss: {hamming_loss_value:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huYs9qo1HQzz",
        "outputId": "66d1b60b-0ce9-4f7a-9e61-20936c54be07"
      },
      "id": "huYs9qo1HQzz",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hamming Loss: 0.0362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBRXJZqdHSGz",
        "outputId": "d35a1a87-7d9e-41fe-e9b8-ddfd658db167"
      },
      "id": "vBRXJZqdHSGz",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Area under the ROC curve (ROC AUC) per ogni etichetta\n",
        "# Utilizzata per valutare le prestazioni di un modello di classificazione binaria al variare della soglia di decisione.\n",
        "# La ROC è creata rappresentando il tasso di vera positività (True Positive Rate, TPR)\n",
        "# rispetto al tasso di falsi positivi (False Positive Rate, FPR) al variare della soglia di decisione.\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'ROC AUC: {roc_auc:.4f}')\n",
        "\n",
        "# Binarizza le etichette\n",
        "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5])\n",
        "n_classes = y_test_binarized.shape[1]\n",
        "\n",
        "# Calcola la curva ROC e l'area sotto la curva (AUC) per ogni etichetta\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Disegna la curva ROC per ogni etichetta\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for label {labels[i]}')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Linea diagonale tratteggiata\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CrdGOXbJHTeg"
      },
      "id": "CrdGOXbJHTeg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('toxicity.h5')\n",
        "model.save('toxicity.keras')"
      ],
      "metadata": {
        "id": "TwL-iQxCTobn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b61c72-ff38-4474-9c47-d31991817c56"
      },
      "id": "TwL-iQxCTobn",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKj0MbHGPMhY"
      },
      "id": "vKj0MbHGPMhY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}